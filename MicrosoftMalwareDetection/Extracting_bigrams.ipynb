{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pixiedust\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process# this is used for multithreading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_grams(n, file):\n",
    "    with open(file,'r') as f:\n",
    "        lines = []\n",
    "        n_grams = [0]*2**(8*n)\n",
    "        for i, line in enumerate(f):\n",
    "            lines.append(line.split(\" \", 1)[1])\n",
    "\n",
    "    if not all(all(word == '??' for word in line.split()) for line in lines):\n",
    "        vectoizer = CountVectorizer(ngram_range=(n,n))\n",
    "        data = vectoizer.fit_transform(lines)    \n",
    "        feature_names = [fn.replace(' ','') for fn in vectoizer.get_feature_names()]\n",
    "        counts_of_features = data.sum(axis=0).tolist()[0]\n",
    "\n",
    "        for i, feature in enumerate(feature_names):\n",
    "            index = int(feature, 16)\n",
    "            n_grams[index] = counts_of_features[i]\n",
    "    \n",
    "    return n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes\\01azqd4InC7m9JpocGv5.bytes\n",
      "bytes\\01IsoiSMh5gxyDYTl4CB.bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10868"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('bytes')\n",
    "files = [\"bytes\\\\\" + i for i in files]\n",
    "print(files[0])\n",
    "print(files[1])\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv = open(r'results_2_gram.csv','w+')\n",
    "feature_names = [\"%0.4X\" % i for i in range(0, 2**(8*2))]\n",
    "\n",
    "feature_names = ['ID'] + feature_names\n",
    "feature_names = \",\".join(map(str,feature_names)) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_csv.write(feature_names)\n",
    "\n",
    "result_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_process_files = files[0:1000]\n",
    "second_process_files = files[1000:2000]\n",
    "third_process_files = files[2000:3000]\n",
    "fourth_process_files = files[3000:4000]\n",
    "fifth_process_files = files[4000:5000]\n",
    "sixth_process_files = files[5000:6000]\n",
    "seventh_process_files = files[6000:7000]\n",
    "eighth_process_files = files[7000:8000]\n",
    "nineth_process_files = files[8000:9000]\n",
    "tenth_process_files = files[9000:10000]\n",
    "eleventh_process_files = files[10000:10868]\n",
    "\n",
    "def first_process():\n",
    "    with open(r'results_2_gram.csv','a+') as result_csv:\n",
    "        count = 1768\n",
    "        for file in first_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def second_process():\n",
    "    with open(r'results_2_gram_2.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in second_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def third_process():\n",
    "    with open(r'results_2_gram_3.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in third_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def fourth_process():\n",
    "    with open(r'results_2_gram_4.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in fourth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def fifth_process():\n",
    "    with open(r'results_2_gram_5.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in fifth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def sixth_process():\n",
    "    with open(r'results_2_gram_6.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in sixth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def seventh_process():\n",
    "    with open(r'results_2_gram_7.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in seventh_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def eighth_process():\n",
    "    with open(r'results_2_gram_8.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in eighth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def nineth_process():\n",
    "    with open(r'results_2_gram_9.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in nineth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def tenth_process():\n",
    "    with open(r'results_2_gram_10.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in tenth_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "def eleventh_process():\n",
    "    with open(r'results_2_gram_11.csv','a+') as result_csv:\n",
    "        result_csv.write(feature_names)\n",
    "        count = 0\n",
    "        for file in eleventh_process_files:\n",
    "            count = count + 1\n",
    "            print(f'Number of files processed = {count}', end=\"\\r\")\n",
    "            file_id = file.split('.')[0].split('\\\\')[1]\n",
    "            n_grams = get_n_grams(file= file, n=2)\n",
    "            line = [file_id] + list(map(str,n_grams))\n",
    "            result_csv.write(\",\".join(map(str,line)) + \"\\n\")\n",
    "\n",
    "p1=Thread(target=first_process)\n",
    "p2=Thread(target=second_process)\n",
    "p3=Thread(target=third_process)\n",
    "p4=Thread(target=fourth_process)\n",
    "p5=Thread(target=fifth_process)\n",
    "p6=Thread(target=sixth_process)\n",
    "p7=Thread(target=seventh_process)\n",
    "p8=Thread(target=eighth_process)\n",
    "p9=Thread(target=nineth_process)\n",
    "p10=Thread(target=tenth_process)\n",
    "p11=Thread(target=eleventh_process)\n",
    "#p1.start() is used to start the thread execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#After completion all the threads are joined\n",
    "p1.join()\n",
    "p2.join()\n",
    "p3.join()\n",
    "p4.join()\n",
    "p5.join()\n",
    "p6.join()\n",
    "p7.join()\n",
    "p8.join()\n",
    "p9.join()\n",
    "p10.join()\n",
    "p11.join()\n",
    "print('----Completed----')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
